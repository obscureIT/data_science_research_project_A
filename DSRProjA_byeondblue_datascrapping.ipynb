{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99e50a2d-7070-4b0b-9880-5c917af6136b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in c:\\users\\akifk\\anaconda3\\lib\\site-packages (2.14.1)\n",
      "Requirement already satisfied: emot in c:\\users\\akifk\\anaconda3\\lib\\site-packages (3.1)\n",
      "Requirement already satisfied: selenium in c:\\users\\akifk\\anaconda3\\lib\\site-packages (4.34.2)\n",
      "Requirement already satisfied: urllib3~=2.5.0 in c:\\users\\akifk\\anaconda3\\lib\\site-packages (from urllib3[socks]~=2.5.0->selenium) (2.5.0)\n",
      "Requirement already satisfied: trio~=0.30.0 in c:\\users\\akifk\\anaconda3\\lib\\site-packages (from selenium) (0.30.0)\n",
      "Requirement already satisfied: trio-websocket~=0.12.2 in c:\\users\\akifk\\anaconda3\\lib\\site-packages (from selenium) (0.12.2)\n",
      "Requirement already satisfied: certifi>=2025.6.15 in c:\\users\\akifk\\anaconda3\\lib\\site-packages (from selenium) (2025.8.3)\n",
      "Requirement already satisfied: typing_extensions~=4.14.0 in c:\\users\\akifk\\anaconda3\\lib\\site-packages (from selenium) (4.14.1)\n",
      "Requirement already satisfied: websocket-client~=1.8.0 in c:\\users\\akifk\\anaconda3\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\akifk\\anaconda3\\lib\\site-packages (from trio~=0.30.0->selenium) (25.3.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\akifk\\anaconda3\\lib\\site-packages (from trio~=0.30.0->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\akifk\\anaconda3\\lib\\site-packages (from trio~=0.30.0->selenium) (3.7)\n",
      "Requirement already satisfied: outcome in c:\\users\\akifk\\anaconda3\\lib\\site-packages (from trio~=0.30.0->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\akifk\\anaconda3\\lib\\site-packages (from trio~=0.30.0->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\akifk\\anaconda3\\lib\\site-packages (from trio~=0.30.0->selenium) (1.17.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\akifk\\anaconda3\\lib\\site-packages (from trio-websocket~=0.12.2->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\akifk\\anaconda3\\lib\\site-packages (from urllib3[socks]~=2.5.0->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\akifk\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.30.0->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\akifk\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.12.2->selenium) (0.14.0)\n",
      "Requirement already satisfied: webdriver_manager in c:\\users\\akifk\\anaconda3\\lib\\site-packages (4.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\akifk\\anaconda3\\lib\\site-packages (from webdriver_manager) (2.32.3)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\akifk\\anaconda3\\lib\\site-packages (from webdriver_manager) (0.21.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\akifk\\anaconda3\\lib\\site-packages (from webdriver_manager) (24.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\akifk\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\akifk\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\akifk\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\akifk\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (2025.8.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji\n",
    "!pip install emot\n",
    "!pip install selenium\n",
    "!pip install webdriver_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48a8ebb6-a818-4db3-b49d-f834ae02d210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import calendar\n",
    "import json\n",
    "\n",
    "\n",
    "import emoji\n",
    "import emot\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "import unicodedata\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81d9a849-7795-4c70-9daa-a093d4cdb9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Directory Check\n",
    "OUTPUT_DIR = \"Data\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f64b3518-5ecc-4525-80f5-cb1da9858410",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping ptsd_trauma:  64%|████████████████████████████████████▍                    | 64/100 [1:28:24<47:13, 78.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to extract post page https://forums.beyondblue.org.au/t5/ptsd-and-trauma/reaching-out-to-abuser/td-p/20973: Message: timeout: Timed out receiving message from renderer: 29.245\n",
      "  (Session info: chrome=139.0.7258.66)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x0xbefd33+62915]\n",
      "\tGetHandleVerifier [0x0xbefd74+62980]\n",
      "\t(No symbol) [0x0xa23e13]\n",
      "\t(No symbol) [0x0xa14aab]\n",
      "\t(No symbol) [0x0xa147e1]\n",
      "\t(No symbol) [0x0xa12784]\n",
      "\t(No symbol) [0x0xa1324d]\n",
      "\t(No symbol) [0x0xa1fa99]\n",
      "\t(No symbol) [0x0xa30f75]\n",
      "\t(No symbol) [0x0xa36956]\n",
      "\t(No symbol) [0x0xa1388d]\n",
      "\t(No symbol) [0x0xa30d1e]\n",
      "\t(No symbol) [0x0xab29cc]\n",
      "\t(No symbol) [0x0xa911d6]\n",
      "\t(No symbol) [0x0xa60833]\n",
      "\t(No symbol) [0x0xa616a4]\n",
      "\tGetHandleVerifier [0x0xe58d23+2590131]\n",
      "\tGetHandleVerifier [0x0xe53f6a+2570234]\n",
      "\tGetHandleVerifier [0x0xc159ea+217722]\n",
      "\tGetHandleVerifier [0x0xc06058+153832]\n",
      "\tGetHandleVerifier [0x0xc0c4bd+179533]\n",
      "\tGetHandleVerifier [0x0xbf7738+94152]\n",
      "\tGetHandleVerifier [0x0xbf78c2+94546]\n",
      "\tGetHandleVerifier [0x0xbe2bda+9322]\n",
      "\tBaseThreadInitThunk [0x0x75f75d49+25]\n",
      "\tRtlInitializeExceptionChain [0x0x770ad1ab+107]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x0x770ad131+561]\n",
      "\n",
      "Failed to extract post page https://forums.beyondblue.org.au/t5/ptsd-and-trauma/i-just-feel-so-lost/td-p/19824: Message: timeout: Timed out receiving message from renderer: 29.441\n",
      "  (Session info: chrome=139.0.7258.66)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x0xbefd33+62915]\n",
      "\tGetHandleVerifier [0x0xbefd74+62980]\n",
      "\t(No symbol) [0x0xa23e13]\n",
      "\t(No symbol) [0x0xa14aab]\n",
      "\t(No symbol) [0x0xa147e1]\n",
      "\t(No symbol) [0x0xa12784]\n",
      "\t(No symbol) [0x0xa1324d]\n",
      "\t(No symbol) [0x0xa1fa99]\n",
      "\t(No symbol) [0x0xa30f75]\n",
      "\t(No symbol) [0x0xa36956]\n",
      "\t(No symbol) [0x0xa1388d]\n",
      "\t(No symbol) [0x0xa30d1e]\n",
      "\t(No symbol) [0x0xab29cc]\n",
      "\t(No symbol) [0x0xa911d6]\n",
      "\t(No symbol) [0x0xa60833]\n",
      "\t(No symbol) [0x0xa616a4]\n",
      "\tGetHandleVerifier [0x0xe58d23+2590131]\n",
      "\tGetHandleVerifier [0x0xe53f6a+2570234]\n",
      "\tGetHandleVerifier [0x0xc159ea+217722]\n",
      "\tGetHandleVerifier [0x0xc06058+153832]\n",
      "\tGetHandleVerifier [0x0xc0c4bd+179533]\n",
      "\tGetHandleVerifier [0x0xbf7738+94152]\n",
      "\tGetHandleVerifier [0x0xbf78c2+94546]\n",
      "\tGetHandleVerifier [0x0xbe2bda+9322]\n",
      "\tBaseThreadInitThunk [0x0x75f75d49+25]\n",
      "\tRtlInitializeExceptionChain [0x0x770ad1ab+107]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x0x770ad131+561]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping ptsd_trauma:  65%|███████████████████████████████████                   | 65/100 [1:32:38<1:16:28, 131.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to extract post page https://forums.beyondblue.org.au/t5/ptsd-and-trauma/my-anger-and-living-with-ptsd/td-p/11763: Message: timeout: Timed out receiving message from renderer: 29.266\n",
      "  (Session info: chrome=139.0.7258.66)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x0xbefd33+62915]\n",
      "\tGetHandleVerifier [0x0xbefd74+62980]\n",
      "\t(No symbol) [0x0xa23e13]\n",
      "\t(No symbol) [0x0xa14aab]\n",
      "\t(No symbol) [0x0xa147e1]\n",
      "\t(No symbol) [0x0xa12784]\n",
      "\t(No symbol) [0x0xa1324d]\n",
      "\t(No symbol) [0x0xa1fa99]\n",
      "\t(No symbol) [0x0xa30f75]\n",
      "\t(No symbol) [0x0xa36956]\n",
      "\t(No symbol) [0x0xa1388d]\n",
      "\t(No symbol) [0x0xa30d1e]\n",
      "\t(No symbol) [0x0xab29cc]\n",
      "\t(No symbol) [0x0xa911d6]\n",
      "\t(No symbol) [0x0xa60833]\n",
      "\t(No symbol) [0x0xa616a4]\n",
      "\tGetHandleVerifier [0x0xe58d23+2590131]\n",
      "\tGetHandleVerifier [0x0xe53f6a+2570234]\n",
      "\tGetHandleVerifier [0x0xc159ea+217722]\n",
      "\tGetHandleVerifier [0x0xc06058+153832]\n",
      "\tGetHandleVerifier [0x0xc0c4bd+179533]\n",
      "\tGetHandleVerifier [0x0xbf7738+94152]\n",
      "\tGetHandleVerifier [0x0xbf78c2+94546]\n",
      "\tGetHandleVerifier [0x0xbe2bda+9322]\n",
      "\tBaseThreadInitThunk [0x0x75f75d49+25]\n",
      "\tRtlInitializeExceptionChain [0x0x770ad1ab+107]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x0x770ad131+561]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping ptsd_trauma:  68%|██████████████████████████████████████                  | 68/100 [1:37:40<55:17, 103.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to extract post page https://forums.beyondblue.org.au/t5/ptsd-and-trauma/dictator/td-p/16682: Message: timeout: Timed out receiving message from renderer: 29.069\n",
      "  (Session info: chrome=139.0.7258.66)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x0xbefd33+62915]\n",
      "\tGetHandleVerifier [0x0xbefd74+62980]\n",
      "\t(No symbol) [0x0xa23e13]\n",
      "\t(No symbol) [0x0xa14aab]\n",
      "\t(No symbol) [0x0xa147e1]\n",
      "\t(No symbol) [0x0xa12784]\n",
      "\t(No symbol) [0x0xa1324d]\n",
      "\t(No symbol) [0x0xa1fa99]\n",
      "\t(No symbol) [0x0xa30f75]\n",
      "\t(No symbol) [0x0xa36956]\n",
      "\t(No symbol) [0x0xa1388d]\n",
      "\t(No symbol) [0x0xa30d1e]\n",
      "\t(No symbol) [0x0xab29cc]\n",
      "\t(No symbol) [0x0xa911d6]\n",
      "\t(No symbol) [0x0xa60833]\n",
      "\t(No symbol) [0x0xa616a4]\n",
      "\tGetHandleVerifier [0x0xe58d23+2590131]\n",
      "\tGetHandleVerifier [0x0xe53f6a+2570234]\n",
      "\tGetHandleVerifier [0x0xc159ea+217722]\n",
      "\tGetHandleVerifier [0x0xc06058+153832]\n",
      "\tGetHandleVerifier [0x0xc0c4bd+179533]\n",
      "\tGetHandleVerifier [0x0xbf7738+94152]\n",
      "\tGetHandleVerifier [0x0xbf78c2+94546]\n",
      "\tGetHandleVerifier [0x0xbe2bda+9322]\n",
      "\tBaseThreadInitThunk [0x0x75f75d49+25]\n",
      "\tRtlInitializeExceptionChain [0x0x770ad1ab+107]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x0x770ad131+561]\n",
      "\n",
      "Failed to extract post page https://forums.beyondblue.org.au/t5/ptsd-and-trauma/after-the-psychologist-psychiatrist-appointment/td-p/19862: Message: timeout: Timed out receiving message from renderer: 29.259\n",
      "  (Session info: chrome=139.0.7258.66)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x0xbefd33+62915]\n",
      "\tGetHandleVerifier [0x0xbefd74+62980]\n",
      "\t(No symbol) [0x0xa23e13]\n",
      "\t(No symbol) [0x0xa14aab]\n",
      "\t(No symbol) [0x0xa147e1]\n",
      "\t(No symbol) [0x0xa12784]\n",
      "\t(No symbol) [0x0xa1324d]\n",
      "\t(No symbol) [0x0xa1fa99]\n",
      "\t(No symbol) [0x0xa30f75]\n",
      "\t(No symbol) [0x0xa36956]\n",
      "\t(No symbol) [0x0xa1388d]\n",
      "\t(No symbol) [0x0xa30d1e]\n",
      "\t(No symbol) [0x0xab29cc]\n",
      "\t(No symbol) [0x0xa911d6]\n",
      "\t(No symbol) [0x0xa60833]\n",
      "\t(No symbol) [0x0xa616a4]\n",
      "\tGetHandleVerifier [0x0xe58d23+2590131]\n",
      "\tGetHandleVerifier [0x0xe53f6a+2570234]\n",
      "\tGetHandleVerifier [0x0xc159ea+217722]\n",
      "\tGetHandleVerifier [0x0xc06058+153832]\n",
      "\tGetHandleVerifier [0x0xc0c4bd+179533]\n",
      "\tGetHandleVerifier [0x0xbf7738+94152]\n",
      "\tGetHandleVerifier [0x0xbf78c2+94546]\n",
      "\tGetHandleVerifier [0x0xbe2bda+9322]\n",
      "\tBaseThreadInitThunk [0x0x75f75d49+25]\n",
      "\tRtlInitializeExceptionChain [0x0x770ad1ab+107]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x0x770ad131+561]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping ptsd_trauma:  75%|██████████████████████████████████████████▊              | 75/100 [1:47:59<30:12, 72.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to extract post page https://forums.beyondblue.org.au/t5/ptsd-and-trauma/i-have-no-one/td-p/506919: Message: timeout: Timed out receiving message from renderer: 29.429\n",
      "  (Session info: chrome=139.0.7258.66)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x0xbefd33+62915]\n",
      "\tGetHandleVerifier [0x0xbefd74+62980]\n",
      "\t(No symbol) [0x0xa23e13]\n",
      "\t(No symbol) [0x0xa14aab]\n",
      "\t(No symbol) [0x0xa147e1]\n",
      "\t(No symbol) [0x0xa12784]\n",
      "\t(No symbol) [0x0xa1324d]\n",
      "\t(No symbol) [0x0xa1fa99]\n",
      "\t(No symbol) [0x0xa30f75]\n",
      "\t(No symbol) [0x0xa36956]\n",
      "\t(No symbol) [0x0xa1388d]\n",
      "\t(No symbol) [0x0xa30d1e]\n",
      "\t(No symbol) [0x0xab29cc]\n",
      "\t(No symbol) [0x0xa911d6]\n",
      "\t(No symbol) [0x0xa60833]\n",
      "\t(No symbol) [0x0xa616a4]\n",
      "\tGetHandleVerifier [0x0xe58d23+2590131]\n",
      "\tGetHandleVerifier [0x0xe53f6a+2570234]\n",
      "\tGetHandleVerifier [0x0xc159ea+217722]\n",
      "\tGetHandleVerifier [0x0xc06058+153832]\n",
      "\tGetHandleVerifier [0x0xc0c4bd+179533]\n",
      "\tGetHandleVerifier [0x0xbf7738+94152]\n",
      "\tGetHandleVerifier [0x0xbf78c2+94546]\n",
      "\tGetHandleVerifier [0x0xbe2bda+9322]\n",
      "\tBaseThreadInitThunk [0x0x75f75d49+25]\n",
      "\tRtlInitializeExceptionChain [0x0x770ad1ab+107]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x0x770ad131+561]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping ptsd_trauma: 100%|████████████████████████████████████████████████████████| 100/100 [2:26:11<00:00, 87.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2000 posts to Data\\posts_ptsd_trauma.csv\n",
      "Saved 994 comments to Data\\comments_ptsd_trauma.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping suicidal_selfharm:  70%|███████████████████████████████████▋               | 70/100 [1:29:01<44:34, 89.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to extract post page https://forums.beyondblue.org.au/t5/suicidal-thoughts-and-self-harm/frustrated-and-stupid-idiot-that-sabotaging-life-by-being-a-joke/td-p/22777: Message: timeout: Timed out receiving message from renderer: 29.074\n",
      "  (Session info: chrome=139.0.7258.66)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x0xbefd33+62915]\n",
      "\tGetHandleVerifier [0x0xbefd74+62980]\n",
      "\t(No symbol) [0x0xa23e13]\n",
      "\t(No symbol) [0x0xa14aab]\n",
      "\t(No symbol) [0x0xa147e1]\n",
      "\t(No symbol) [0x0xa12784]\n",
      "\t(No symbol) [0x0xa1324d]\n",
      "\t(No symbol) [0x0xa1fa99]\n",
      "\t(No symbol) [0x0xa30f75]\n",
      "\t(No symbol) [0x0xa36956]\n",
      "\t(No symbol) [0x0xa1388d]\n",
      "\t(No symbol) [0x0xa30d1e]\n",
      "\t(No symbol) [0x0xab29cc]\n",
      "\t(No symbol) [0x0xa911d6]\n",
      "\t(No symbol) [0x0xa60833]\n",
      "\t(No symbol) [0x0xa616a4]\n",
      "\tGetHandleVerifier [0x0xe58d23+2590131]\n",
      "\tGetHandleVerifier [0x0xe53f6a+2570234]\n",
      "\tGetHandleVerifier [0x0xc159ea+217722]\n",
      "\tGetHandleVerifier [0x0xc06058+153832]\n",
      "\tGetHandleVerifier [0x0xc0c4bd+179533]\n",
      "\tGetHandleVerifier [0x0xbf7738+94152]\n",
      "\tGetHandleVerifier [0x0xbf78c2+94546]\n",
      "\tGetHandleVerifier [0x0xbe2bda+9322]\n",
      "\tBaseThreadInitThunk [0x0x75f75d49+25]\n",
      "\tRtlInitializeExceptionChain [0x0x770ad1ab+107]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x0x770ad131+561]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping suicidal_selfharm:  82%|█████████████████████████████████████████▊         | 82/100 [1:47:49<28:10, 93.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to extract post page https://forums.beyondblue.org.au/t5/suicidal-thoughts-and-self-harm/the-covert-narcissist-is-the-weak-one/td-p/31617: Message: timeout: Timed out receiving message from renderer: 29.392\n",
      "  (Session info: chrome=139.0.7258.66)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x0xbefd33+62915]\n",
      "\tGetHandleVerifier [0x0xbefd74+62980]\n",
      "\t(No symbol) [0x0xa23e13]\n",
      "\t(No symbol) [0x0xa14aab]\n",
      "\t(No symbol) [0x0xa147e1]\n",
      "\t(No symbol) [0x0xa12784]\n",
      "\t(No symbol) [0x0xa1324d]\n",
      "\t(No symbol) [0x0xa1fa99]\n",
      "\t(No symbol) [0x0xa30f75]\n",
      "\t(No symbol) [0x0xa36956]\n",
      "\t(No symbol) [0x0xa1388d]\n",
      "\t(No symbol) [0x0xa30d1e]\n",
      "\t(No symbol) [0x0xab29cc]\n",
      "\t(No symbol) [0x0xa911d6]\n",
      "\t(No symbol) [0x0xa60833]\n",
      "\t(No symbol) [0x0xa616a4]\n",
      "\tGetHandleVerifier [0x0xe58d23+2590131]\n",
      "\tGetHandleVerifier [0x0xe53f6a+2570234]\n",
      "\tGetHandleVerifier [0x0xc159ea+217722]\n",
      "\tGetHandleVerifier [0x0xc06058+153832]\n",
      "\tGetHandleVerifier [0x0xc0c4bd+179533]\n",
      "\tGetHandleVerifier [0x0xbf7738+94152]\n",
      "\tGetHandleVerifier [0x0xbf78c2+94546]\n",
      "\tGetHandleVerifier [0x0xbe2bda+9322]\n",
      "\tBaseThreadInitThunk [0x0x75f75d49+25]\n",
      "\tRtlInitializeExceptionChain [0x0x770ad1ab+107]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x0x770ad131+561]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping suicidal_selfharm:  90%|█████████████████████████████████████████████▉     | 90/100 [2:00:46<16:01, 96.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to extract post page https://forums.beyondblue.org.au/t5/suicidal-thoughts-and-self-harm/what-to-do-if-person-who-saved-your-life-no-longer-talks-to-you/td-p/14350: Message: timeout: Timed out receiving message from renderer: 29.288\n",
      "  (Session info: chrome=139.0.7258.66)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x0xbefd33+62915]\n",
      "\tGetHandleVerifier [0x0xbefd74+62980]\n",
      "\t(No symbol) [0x0xa23e13]\n",
      "\t(No symbol) [0x0xa14aab]\n",
      "\t(No symbol) [0x0xa147e1]\n",
      "\t(No symbol) [0x0xa12784]\n",
      "\t(No symbol) [0x0xa1324d]\n",
      "\t(No symbol) [0x0xa1fa99]\n",
      "\t(No symbol) [0x0xa30f75]\n",
      "\t(No symbol) [0x0xa36956]\n",
      "\t(No symbol) [0x0xa1388d]\n",
      "\t(No symbol) [0x0xa30d1e]\n",
      "\t(No symbol) [0x0xab29cc]\n",
      "\t(No symbol) [0x0xa911d6]\n",
      "\t(No symbol) [0x0xa60833]\n",
      "\t(No symbol) [0x0xa616a4]\n",
      "\tGetHandleVerifier [0x0xe58d23+2590131]\n",
      "\tGetHandleVerifier [0x0xe53f6a+2570234]\n",
      "\tGetHandleVerifier [0x0xc159ea+217722]\n",
      "\tGetHandleVerifier [0x0xc06058+153832]\n",
      "\tGetHandleVerifier [0x0xc0c4bd+179533]\n",
      "\tGetHandleVerifier [0x0xbf7738+94152]\n",
      "\tGetHandleVerifier [0x0xbf78c2+94546]\n",
      "\tGetHandleVerifier [0x0xbe2bda+9322]\n",
      "\tBaseThreadInitThunk [0x0x75f75d49+25]\n",
      "\tRtlInitializeExceptionChain [0x0x770ad1ab+107]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x0x770ad131+561]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping suicidal_selfharm:  92%|██████████████████████████████████████████████▉    | 92/100 [2:14:33<11:42, 87.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load page https://forums.beyondblue.org.au/t5/suicidal-thoughts-and-self-harm/bd-p/c1-sc2-b4/page/93?sort=recent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error scraping staying_well: Could not reach host. Are you offline?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping treatments: 100%|█████████████████████████████████████████████████████████| 100/100 [1:42:04<00:00, 61.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2000 posts to Data\\posts_treatments.csv\n",
      "Saved 1000 comments to Data\\comments_treatments.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping relationships: 100%|██████████████████████████████████████████████████████| 100/100 [1:39:30<00:00, 59.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2000 posts to Data\\posts_relationships.csv\n",
      "Saved 1000 comments to Data\\comments_relationships.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping supporting_friends: 100%|█████████████████████████████████████████████████| 100/100 [1:41:02<00:00, 60.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2000 posts to Data\\posts_supporting_friends.csv\n",
      "Saved 1000 comments to Data\\comments_supporting_friends.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping long_term_support:  17%|███████▉                                       | 17/100 [3:15:00<15:52:04, 688.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 321 posts to Data\\posts_long_term_support.csv\n",
      "Saved 171 comments to Data\\comments_long_term_support.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping young_people: 100%|███████████████████████████████████████████████████████| 100/100 [1:34:17<00:00, 56.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2000 posts to Data\\posts_young_people.csv\n",
      "Saved 1000 comments to Data\\comments_young_people.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Sex_identity:  78%|███████████████████████████████████████████▋            | 78/100 [1:25:15<24:02, 65.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1532 posts to Data\\posts_Sex_identity.csv\n",
      "Saved 782 comments to Data\\comments_Sex_identity.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Multiculture:  25%|██████████████                                          | 25/100 [29:40<1:29:02, 71.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 508 posts to Data\\posts_Multiculture.csv\n",
      "Saved 258 comments to Data\\comments_Multiculture.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Grief_loss:  87%|██████████████████████████████████████████████████▍       | 87/100 [1:25:48<12:49, 59.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1729 posts to Data\\posts_Grief_loss.csv\n",
      "Saved 879 comments to Data\\comments_Grief_loss.csv\n"
     ]
    }
   ],
   "source": [
    "KAOMOJI_FILE = \"kaomoji_to_text.json\"\n",
    "if os.path.exists(KAOMOJI_FILE):\n",
    "    with open(KAOMOJI_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "        kaomoji_to_text = json.load(f)\n",
    "else:0\n",
    "    kaomoji_to_text = {}\n",
    "\n",
    "\n",
    "\n",
    "def clean_text(s):\n",
    "    if not s:\n",
    "        return \"\"\n",
    "    s = ''.join(c for c in s if unicodedata.category(c)[0] != 'C' and c != '\\uFFFD')\n",
    "    return s.replace('\\xa0', ' ').replace('\\u200e', '').strip()\n",
    "\n",
    "def standardize_date(raw_date: str) -> str:\n",
    "    s = clean_text(raw_date)\n",
    "    today = datetime.now()\n",
    "    weekdays = [d.lower() for d in calendar.day_name]\n",
    "    s_lower = s.lower()\n",
    "\n",
    "    # Handle relative dates\n",
    "    if s_lower in weekdays:\n",
    "        delta = (today.weekday() - weekdays.index(s_lower)) % 7\n",
    "        return (today - timedelta(days=delta)).strftime(\"%d-%m-%Y\")\n",
    "    if \"yesterday\" in s_lower:\n",
    "        return (today - timedelta(days=1)).strftime(\"%d-%m-%Y\")\n",
    "    if \"today\" in s_lower:\n",
    "        return today.strftime(\"%d-%m-%Y\")\n",
    "    if \"week\" in s_lower:\n",
    "        n = int(re.search(r\"(\\d+)\", s_lower).group(1)) if re.search(r\"\\d+\", s_lower) else 1\n",
    "        return (today - timedelta(weeks=n)).strftime(\"%d-%m-%Y\")\n",
    "    if \"month\" in s_lower:\n",
    "        n = int(re.search(r\"(\\d+)\", s_lower).group(1)) if re.search(r\"\\d+\", s_lower) else 1\n",
    "        return (today - timedelta(days=30*n)).strftime(\"%d-%m-%Y\")\n",
    "\n",
    "    # Try most relevant date formats\n",
    "    fmts = [\n",
    "        \"%Y-%m-%dT%H:%M:%SZ\",\n",
    "        \"%Y-%m-%dT%H:%M:%S\",\n",
    "        \"%Y-%m-%d %H:%M\",\n",
    "        \"%d-%m-%Y %H:%M\",\n",
    "        \"%d-%m-%Y %I:%M %p\",\n",
    "        \"%d/%m/%Y %H:%M\",\n",
    "        \"%d/%m/%Y %I:%M %p\",\n",
    "        \"%d-%m-%Y%H:%M\",\n",
    "        \"%Y-%m-%d%H:%M\",\n",
    "        \"%d/%m/%Y%H:%M\",\n",
    "    ]\n",
    "    for fmt in fmts:\n",
    "        try:\n",
    "            dt = datetime.strptime(s, fmt)\n",
    "            return dt.strftime(\"%d-%m-%Y\")\n",
    "        except Exception:\n",
    "            continue\n",
    "    # Date only formats (no time info)\n",
    "    date_fmts = [\n",
    "        \"%d-%m-%Y\", \"%Y-%m-%d\", \"%d/%m/%Y\"\n",
    "    ]\n",
    "    for fmt in date_fmts:\n",
    "        try:\n",
    "            dt = datetime.strptime(s, fmt)\n",
    "            return dt.strftime(\"%d-%m-%Y\")\n",
    "        except Exception:\n",
    "            continue\n",
    "    # Fallback: regex for non-standard\n",
    "    m = re.match(r\"(\\d{2})-(\\d{2})-(\\d{4})\", s)\n",
    "    if m:\n",
    "        return f\"{m.group(1)}-{m.group(2)}-{m.group(3)}\"\n",
    "    return s\n",
    "\n",
    "def convert_emojis_emoticons(text: str) -> str:\n",
    "    text = clean_text(text)\n",
    "    for k, v in kaomoji_to_text.items():\n",
    "        text = text.replace(k, f\" {v} \")\n",
    "    e = emot.core.emot()\n",
    "    emo = e.emoticons(text)\n",
    "    for orig, mean in zip(emo[\"value\"], emo[\"mean\"]):\n",
    "        text = text.replace(orig, f\" {mean} \")\n",
    "    text = emoji.demojize(text)\n",
    "    return text.strip().lower()\n",
    "\n",
    "def get_existing_ids(filepath, id_column):\n",
    "    if os.path.exists(filepath):\n",
    "        try:\n",
    "            df = pd.read_csv(filepath)\n",
    "            return set(df[id_column].astype(str))\n",
    "        except Exception:\n",
    "            return set()\n",
    "    else:\n",
    "        return set()\n",
    "\n",
    "def make_comment_id(msg, post_id, comment_content):\n",
    "    comment_id = (msg.get('data-message-id') or msg.get('id') or '').strip()\n",
    "    if comment_id and comment_id.lower() not in ['lineardisplaymessageviewwrapper', '']:\n",
    "        return comment_id\n",
    "    hash_part = hashlib.sha256(comment_content.encode('utf-8')).hexdigest()[:10]\n",
    "    return f\"{post_id}_c{hash_part}\"\n",
    "\n",
    "def extract_comment_date(msg):\n",
    "    time_elem = msg.find(\"time\")\n",
    "    if time_elem:\n",
    "        if time_elem.has_attr('datetime'):\n",
    "            return standardize_date(time_elem['datetime'])\n",
    "        elif time_elem.has_attr('title'):\n",
    "            return standardize_date(time_elem['title'])\n",
    "        elif time_elem.text.strip():\n",
    "            return standardize_date(time_elem.text)\n",
    "    date_elem = msg.find(\"span\", class_=\"local-friendly-date\")\n",
    "    if date_elem:\n",
    "        if date_elem.has_attr('title') and date_elem['title'].strip():\n",
    "            return standardize_date(date_elem['title'])\n",
    "        elif date_elem.text.strip():\n",
    "            return standardize_date(date_elem.text)\n",
    "    datetime_elem = msg.find(\"span\", class_=\"DateTime\")\n",
    "    if datetime_elem and datetime_elem.text.strip():\n",
    "        return standardize_date(datetime_elem.text)\n",
    "    if msg.has_attr('data-message-timestamp'):\n",
    "        try:\n",
    "            ts = int(msg['data-message-timestamp'])\n",
    "            return datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M')\n",
    "        except Exception:\n",
    "            pass\n",
    "    return ''\n",
    "\n",
    "def comment_scraping(driver, post_url, post_id, category, max_comments=200, retry=3, polite_delay=1):\n",
    "    comments = []\n",
    "    comments_csv = os.path.join(OUTPUT_DIR, f\"comments_{category}.csv\")\n",
    "    existing_comment_ids = get_existing_ids(comments_csv, \"Comment ID\")\n",
    "    url = post_url\n",
    "    scraped = 0\n",
    "    for page in range(1, 100):  # will break on next not found\n",
    "        if scraped >= max_comments:\n",
    "            break\n",
    "        success = False\n",
    "        for attempt in range(retry):\n",
    "            try:\n",
    "                driver.get(url)\n",
    "                WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.CLASS_NAME, \"linear-message-list\"))\n",
    "                )\n",
    "                soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "                success = True\n",
    "                break\n",
    "            except Exception:\n",
    "                time.sleep(2)\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        section = soup.find(\"div\", class_=\"linear-message-list\")\n",
    "        if not section:\n",
    "            break\n",
    "\n",
    "        msgs = section.find_all(\"div\", class_=\"lia-message-view-display\")\n",
    "        for msg in msgs:\n",
    "            if scraped >= max_comments:\n",
    "                break\n",
    "            content_elem = msg.find(\"div\", class_=\"lia-message-body-content\")\n",
    "            comment_content = convert_emojis_emoticons(content_elem.get_text(\"\\n\", strip=True)) if content_elem else \"\"\n",
    "            comment_id = make_comment_id(msg, post_id, comment_content)\n",
    "            if comment_id in existing_comment_ids:\n",
    "                continue\n",
    "            author_elem = msg.find(\"a\", class_=\"lia-user-name-link\")\n",
    "            comment_author = clean_text(author_elem.get_text(strip=True)) if author_elem else \"\"\n",
    "            comment_date = extract_comment_date(msg)\n",
    "            support_elem = msg.find(\"span\", {\"id\": re.compile(r\"^kudos-count-\")})\n",
    "            if not support_elem:\n",
    "                support_elem = msg.find(\"span\", class_=\"lia-component-kudos-widget-message-kudos-count\")\n",
    "            comment_support = support_elem.text.strip() if support_elem else \"0\"\n",
    "            comment_row = {\n",
    "                \"Comment ID\": comment_id,\n",
    "                \"Post ID\": post_id,\n",
    "                \"Category\": category,\n",
    "                \"Comment Author\": comment_author,\n",
    "                \"Comment Date\": comment_date,\n",
    "                \"Comment Content\": comment_content,\n",
    "                \"Comment Support\": comment_support,\n",
    "                \"Post URL\": post_url\n",
    "            }\n",
    "            comments.append(comment_row)\n",
    "            existing_comment_ids.add(comment_id)\n",
    "            scraped += 1\n",
    "        nxt = soup.find(\"a\", rel=\"next\")\n",
    "        if not nxt or not nxt.get(\"href\"):\n",
    "            break\n",
    "        url = \"https://forums.beyondblue.org.au\" + nxt[\"href\"] if nxt[\"href\"].startswith(\"/\") else nxt[\"href\"]\n",
    "        time.sleep(polite_delay)\n",
    "    comments = sorted(comments, key=lambda c: c[\"Comment Date\"])\n",
    "    return comments\n",
    "\n",
    "def beyondblue_scraping(tag: str, start_url: str, pages: int = 20, polite_delay=2):\n",
    "    posts_csv = os.path.join(OUTPUT_DIR, f\"posts_{tag}.csv\")\n",
    "    comments_csv = os.path.join(OUTPUT_DIR, f\"comments_{tag}.csv\")\n",
    "    existing_post_ids = get_existing_ids(posts_csv, \"Post ID\")\n",
    "    existing_comment_ids = get_existing_ids(comments_csv, \"Comment ID\")\n",
    "    all_posts = []\n",
    "    all_comments = []\n",
    "\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "    driver.set_page_load_timeout(30)\n",
    "    url = start_url\n",
    "    try:\n",
    "        for p in tqdm(range(1, pages + 1), desc=f\"Scraping {tag}\"):\n",
    "            for attempt in range(3):\n",
    "                try:\n",
    "                    driver.get(url)\n",
    "                    WebDriverWait(driver, 10).until(\n",
    "                        EC.presence_of_element_located((By.CLASS_NAME, \"custom-message-list\"))\n",
    "                    )\n",
    "                    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "                    break\n",
    "                except Exception:\n",
    "                    if attempt == 2:\n",
    "                        print(f\"Failed to load page {url}\")\n",
    "                        return\n",
    "                    time.sleep(2)\n",
    "            container = soup.find(\"div\", class_=\"custom-message-list all-discussions\")\n",
    "            if not container:\n",
    "                break\n",
    "            for art in container.find_all(\"article\"):\n",
    "                aside = art.find(\"aside\")\n",
    "                cat_div = aside.find(\"div\", class_=\"custom-tile-category-content\") if aside else None\n",
    "                post_cat = clean_text(cat_div.find(\"a\").text.strip()) if cat_div and cat_div.find(\"a\") else tag\n",
    "                # --- DATE ---\n",
    "                time_el = cat_div.find(\"time\") if cat_div else None\n",
    "                if time_el and time_el.has_attr('datetime'):\n",
    "                    raw_date = time_el['datetime']\n",
    "                elif time_el and time_el.has_attr('title'):\n",
    "                    raw_date = time_el['title']\n",
    "                elif time_el:\n",
    "                    raw_date = time_el.text.strip()\n",
    "                else:\n",
    "                    raw_date = \"\"\n",
    "                date = standardize_date(raw_date)\n",
    "                # --- SUPPORT AND REPLIES ---\n",
    "                support_li = art.find(\"li\", class_=\"custom-tile-kudos\")\n",
    "                support_span = support_li.find(\"span\") if support_li else None\n",
    "                post_support = support_span.text.strip() if support_span else \"0\"\n",
    "\n",
    "                replies_li = art.find(\"li\", class_=\"custom-tile-replies\")\n",
    "                replies_b = replies_li.find(\"b\") if replies_li else None\n",
    "                total_comment_count = replies_b.text.strip() if replies_b else \"0\"\n",
    "                # --- POST TITLE/URL/CONTENT ---\n",
    "                h3 = art.find(\"h3\")\n",
    "                link_els = h3.find_all(\"a\") if h3 else []\n",
    "                link_el = link_els[1] if len(link_els) > 1 else (link_els[0] if link_els else None)\n",
    "                post_link = link_el[\"href\"] if link_el and link_el.has_attr(\"href\") else \"\"\n",
    "                post_id = post_link.rstrip(\"/\").split(\"/\")[-1] if post_link else \"\"\n",
    "                if not post_id or post_id in existing_post_ids:\n",
    "                    continue\n",
    "                full_link = \"https://forums.beyondblue.org.au\" + post_link if post_link.startswith(\"/\") else post_link\n",
    "                title = convert_emojis_emoticons(link_el.text.strip()) if link_el else \"\"\n",
    "                body = art.find(\"p\", class_=\"body-text\")\n",
    "                content = convert_emojis_emoticons(body.text.strip()) if body else \"\"\n",
    "                auth_div = aside.find(\"div\", class_=\"custom-tile-author-info\") if aside else None\n",
    "                auth_a = auth_div.find(\"a\") if auth_div else None\n",
    "                author = clean_text(auth_a.get_text(strip=True)) if auth_a else \"\"\n",
    "                post_content = content\n",
    "                # --- Get real post support from detail page ---\n",
    "                for attempt in range(3):\n",
    "                    try:\n",
    "                        driver.execute_script(\"window.open('');\")\n",
    "                        driver.switch_to.window(driver.window_handles[1])\n",
    "                        driver.get(full_link)\n",
    "                        WebDriverWait(driver, 10).until(\n",
    "                            EC.presence_of_element_located((By.CLASS_NAME, \"lia-message-body-content\"))\n",
    "                        )\n",
    "                        post_soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "                        content_elems = post_soup.find_all(\"div\", class_=\"lia-message-body-content\")\n",
    "                        if content_elems:\n",
    "                            post_content = \"\\n\".join([convert_emojis_emoticons(elem.get_text(\"\\n\", strip=True)) for elem in content_elems if elem.get_text(strip=True)])\n",
    "                        # Get support count from first post in thread\n",
    "                        support_span_detail = post_soup.find(\"span\", {\"id\": re.compile(r\"^kudos-count-\")})\n",
    "                        if not support_span_detail:\n",
    "                            support_span_detail = post_soup.find(\"span\", class_=\"lia-component-kudos-widget-message-kudos-count\")\n",
    "                        if support_span_detail:\n",
    "                            post_support = support_span_detail.text.strip()\n",
    "                        # Get post date from detail if missing\n",
    "                        time_elem = post_soup.find(\"time\")\n",
    "                        if not date and time_elem:\n",
    "                            if time_elem.has_attr(\"datetime\"):\n",
    "                                date = standardize_date(time_elem[\"datetime\"])\n",
    "                            elif time_elem.has_attr(\"title\"):\n",
    "                                date = standardize_date(time_elem[\"title\"])\n",
    "                            else:\n",
    "                                date = standardize_date(time_elem.text.strip())\n",
    "                        # Scrape all comments (not for count, but real data)\n",
    "                        comments = comment_scraping(driver, full_link, post_id, tag, max_comments=200)\n",
    "                        new_comments = []\n",
    "                        for c in comments:\n",
    "                            if c[\"Comment ID\"] not in existing_comment_ids:\n",
    "                                new_comments.append(c)\n",
    "                                existing_comment_ids.add(c[\"Comment ID\"])\n",
    "                        all_comments.extend(new_comments)\n",
    "                        driver.close()\n",
    "                        driver.switch_to.window(driver.window_handles[0])\n",
    "                        break\n",
    "                    except Exception as e:\n",
    "                        if attempt == 2:\n",
    "                            print(f\"Failed to extract post page {full_link}: {e}\")\n",
    "                            try:\n",
    "                                driver.close()\n",
    "                                driver.switch_to.window(driver.window_handles[0])\n",
    "                            except: pass\n",
    "                        else:\n",
    "                            time.sleep(2)\n",
    "                post_data = {\n",
    "                    \"Post ID\": post_id,\n",
    "                    \"Category\": post_cat,\n",
    "                    \"Post Title\": title,\n",
    "                    \"Post Author\": author,\n",
    "                    \"Post Date\": date,\n",
    "                    \"Post Content\": post_content,\n",
    "                    \"Support Count\": post_support,\n",
    "                    \"Total Number of Comments\": total_comment_count,\n",
    "                    \"Post URL\": full_link\n",
    "                }\n",
    "                all_posts.append(post_data)\n",
    "                existing_post_ids.add(post_id)\n",
    "                time.sleep(polite_delay)\n",
    "            nxt_li = soup.find(\"li\", class_=\"lia-paging-page-next\")\n",
    "            if nxt_li and nxt_li.find(\"a\"):\n",
    "                next_href = nxt_li.find(\"a\")[\"href\"]\n",
    "                url = \"https://forums.beyondblue.org.au\" + next_href if next_href.startswith(\"/\") else next_href\n",
    "            else:\n",
    "                break\n",
    "            if p % 5 == 0:\n",
    "                dfp = pd.DataFrame(all_posts)\n",
    "                dfp.sort_values(by=\"Post Date\", inplace=True)\n",
    "                dfp.to_csv(posts_csv, index=False)\n",
    "                dfc = pd.DataFrame(all_comments)\n",
    "                dfc.sort_values(by=\"Comment Date\", inplace=True)\n",
    "                dfc.to_csv(comments_csv, index=False)\n",
    "    finally:\n",
    "        driver.quit()\n",
    "    if all_posts:\n",
    "        dfp = pd.DataFrame(all_posts)\n",
    "        if os.path.exists(posts_csv):\n",
    "            dfp_existing = pd.read_csv(posts_csv)\n",
    "            dfp = pd.concat([dfp_existing, dfp], ignore_index=True)\n",
    "            dfp.drop_duplicates(subset=[\"Post ID\"], inplace=True)\n",
    "        dfp.sort_values(by=\"Post Date\", inplace=True)\n",
    "        dfp.to_csv(posts_csv, index=False)\n",
    "        print(f\"Saved {len(dfp)} posts to {posts_csv}\")\n",
    "    if all_comments:\n",
    "        dfc = pd.DataFrame(all_comments)\n",
    "        if os.path.exists(comments_csv):\n",
    "            dfc_existing = pd.read_csv(comments_csv)\n",
    "            dfc = pd.concat([dfc_existing, dfc], ignore_index=True)\n",
    "            dfc.drop_duplicates(subset=[\"Comment ID\"], inplace=True)\n",
    "        dfc.sort_values(by=\"Comment Date\", inplace=True)\n",
    "        dfc.to_csv(comments_csv, index=False)\n",
    "        print(f\"Saved {len(dfc)} comments to {comments_csv}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mental_health_urls = {\n",
    "        #\"anxiety\":      \"https://forums.beyondblue.org.au/t5/anxiety/bd-p/c1-sc2-b1?&sort=recent\",\n",
    "        #\"depression\":   \"https://forums.beyondblue.org.au/t5/depression/bd-p/c1-sc2-b2?&sort=recent\",\n",
    "        \"ptsd_trauma\":  \"https://forums.beyondblue.org.au/t5/ptsd-and-trauma/bd-p/c1-sc2-b3?&sort=recent\",\n",
    "        \"suicidal_selfharm\": \"https://forums.beyondblue.org.au/t5/suicidal-thoughts-and-self-harm/bd-p/c1-sc2-b4?&sort=recent\",\n",
    "        \"staying_well\": \"https://forums.beyondblue.org.au/t5/staying-well/bd-p/c1-sc3-b1?&sort=recent\",\n",
    "        \"treatments\":   \"https://forums.beyondblue.org.au/t5/treatments-health-professionals/bd-p/c1-sc3-b2?&sort=recent\",\n",
    "        \"relationships\":\"https://forums.beyondblue.org.au/t5/relationship-and-family-issues/bd-p/c1-sc3-b3?&sort=recent\",\n",
    "        \"supporting_friends\": \"https://forums.beyondblue.org.au/t5/supporting-family-and-friends/bd-p/c1-sc3-b4?&sort=recent\",\n",
    "        \"long_term_support\":  \"https://forums.beyondblue.org.au/t5/long-term-support-over-the/bd-p/c1-sc3-b5?&sort=recent\",\n",
    "        \"young_people\": \"https://forums.beyondblue.org.au/t5/young-people/bd-p/c1-sc4-b1?&sort=recent\",\n",
    "        \"Sex_identity\": \"https://forums.beyondblue.org.au/t5/sexuality-and-gender-identity/bd-p/c1-sc4-b2?&sort=recent\",\n",
    "        \"Multiculture\":  \"https://forums.beyondblue.org.au/t5/multicultural-experiences/bd-p/c1-sc4-b3?&sort=recent\",\n",
    "        \"Grief_loss\":    \"https://forums.beyondblue.org.au/t5/grief-and-loss/bd-p/c1-sc4-b4?&sort=recent\"\n",
    "    }\n",
    "    for tag, addr in mental_health_urls.items():\n",
    "        try:\n",
    "            beyondblue_scraping(tag, addr, pages=100)\n",
    "        except Exception as e:\n",
    "            print(f\"Error scraping {tag}: {e}\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f3d33b-fc3b-4ea1-af81-83baa4ba4474",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
